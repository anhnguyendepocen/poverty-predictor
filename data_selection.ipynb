{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment with Descartes Labs API and inventory datasets**\n",
    "\n",
    "Let's see what datasets are available via the Descartes Labs API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting packages\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# import shapely.geometry\n",
    "# import cartopy\n",
    "\n",
    "# Import Descartes Labs library \n",
    "# import descarteslabs as dl\n",
    "# from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = dl.metadata.sources()\n",
    "pprint (sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find potential matches\n",
    "matches = dl.places.find('honduras')\n",
    "pprint(matches)\n",
    "# The first one looks good to me, so lets make that our area of interest.\n",
    "aoi = matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aoi = matches[0]\n",
    "shape = dl.places.shape(aoi['slug'], geom='low')\n",
    "bbox = shape['bbox']\n",
    "\n",
    "# Lets load up the Albers Equal Area projection.\n",
    "lonlat_crs = cartopy.crs.PlateCarree()\n",
    "albers = cartopy.crs.AlbersEqualArea(central_latitude=36.0, central_longitude=-105)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 8))\n",
    "ax = plt.subplot(projection=albers) # Specify projection of the map here\n",
    "shp = shapely.geometry.shape(shape['geometry'])\n",
    "\n",
    "# When adding a geometry in latlon coordinates, specify the latlon projection\n",
    "ax.add_geometries([shp], lonlat_crs)\n",
    "\n",
    "# You can set extents in latlon, as long as you specify the projection with `crs`\n",
    "ax.set_extent((bbox[0], bbox[2], bbox[1], bbox[3]), crs=lonlat_crs)\n",
    "ax.gridlines(crs=lonlat_crs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "feature_collection = dl.metadata.search(products='landsat:LC08:PRE:TOAR', start_time='2017-03-12',\n",
    "                                        end_time='2015-03-20', limit=10, place=aoi['slug'])\n",
    "\n",
    "print len(feature_collection['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr, meta = dl.raster.ndarray(\n",
    "    f0['id'],\n",
    "    bands=['red', 'green', 'blue', 'alpha'],\n",
    "    scales=[[0,4000], [0, 4000], [0, 4000], None],\n",
    "    data_type='Byte',\n",
    "    resolution=30,\n",
    "    cutline=shape['geometry'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,16])\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test technique for classification of Landsat imagery**\n",
    "\n",
    "Using scikit-learn learn and gdal, we can create training data to classify urban areas in imagery. I am following along with this tutorial: https://www.machinalis.com/blog/python-for-geospatial-data-processing/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from osgeo import gdal\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data includes a preprocessed Landsat image, shapefile training data broken into five classes, and data to test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in function OpenEx>\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "print (gdal.OpenEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A list of \"random\" colors (for a nicer output)\n",
    "COLORS = [\"#000000\", \"#FFFF00\", \"#1CE6FF\", \"#FF34FF\", \"#FF4A46\", \"#008941\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I define functions to aid in rasterizing important vector datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mask_from_vector(vector_data_path, cols, rows, geo_transform,\n",
    "                            projection, target_value=1):\n",
    "    \"\"\"Rasterize the given vector (wrapper for gdal.RasterizeLayer).\"\"\"\n",
    "    data_source = gdal.OpenEx(vector_data_path, gdal.OF_VECTOR)\n",
    "    layer = data_source.GetLayer(0)\n",
    "    driver = gdal.GetDriverByName('MEM')  # In memory dataset\n",
    "    target_ds = driver.Create('', cols, rows, 1, gdal.GDT_UInt16)\n",
    "    target_ds.SetGeoTransform(geo_transform)\n",
    "    target_ds.SetProjection(projection)\n",
    "    gdal.RasterizeLayer(target_ds, [1], layer, burn_values=[target_value])\n",
    "    return target_ds\n",
    "\n",
    "def vectors_to_raster(file_paths, rows, cols, geo_transform, projection):\n",
    "    \"\"\"Rasterize the vectors in the given directory in a single image.\"\"\"\n",
    "    from osgeo import gdal\n",
    "    gdal.UseExceptions()\n",
    "    labeled_pixels = np.zeros((rows, cols))\n",
    "    for i, path in enumerate(file_paths):\n",
    "        label = i+1\n",
    "        ds = create_mask_from_vector(path, cols, rows, geo_transform,\n",
    "                                     projection, target_value=label)\n",
    "        band = ds.GetRasterBand(1)\n",
    "        labeled_pixels += band.ReadAsArray()\n",
    "        ds = None\n",
    "    return labeled_pixels\n",
    "\n",
    "\n",
    "def write_geotiff(fname, data, geo_transform, projection):\n",
    "    \"\"\"Create a GeoTIFF file with the given data.\"\"\"\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    rows, cols = data.shape\n",
    "    dataset = driver.Create(fname, cols, rows, 1, gdal.GDT_Byte)\n",
    "    dataset.SetGeoTransform(geo_transform)\n",
    "    dataset.SetProjection(projection)\n",
    "    band = dataset.GetRasterBand(1)\n",
    "    band.WriteArray(data)\n",
    "    dataset = None  # Close the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to define our datasets, including train, test, and imagery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raster_data_path = \"data/image/2298119ene2016recorteTT.tif\"\n",
    "output_fname = \"classification.tiff\"\n",
    "train_data_path = \"data/test/\"\n",
    "validation_data_path = \"data/train/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we let's stuff all our pixel values into a stack of numpy arrrays for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raster_dataset = gdal.Open(raster_data_path, gdal.GA_ReadOnly)\n",
    "geo_transform = raster_dataset.GetGeoTransform()\n",
    "proj = raster_dataset.GetProjectionRef()\n",
    "bands_data = []\n",
    "for b in range(1, raster_dataset.RasterCount+1):\n",
    "    band = raster_dataset.GetRasterBand(b)\n",
    "    bands_data.append(band.ReadAsArray())\n",
    "\n",
    "bands_data = np.dstack(bands_data)\n",
    "rows, cols, n_bands = bands_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to rasterize our vector datasets using the previously defined functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(train_data_path) if f.endswith('.shp')]\n",
    "classes = [f.split('.')[0] for f in files]\n",
    "shapefiles = [os.path.join(train_data_path, f)\n",
    "              for f in files if f.endswith('.shp')]\n",
    "\n",
    "labeled_pixels = vectors_to_raster(shapefiles, rows, cols, geo_transform,\n",
    "                                   proj)\n",
    "is_train = np.nonzero(labeled_pixels)\n",
    "training_labels = labeled_pixels[is_train]\n",
    "training_samples = bands_data[is_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "print (gdal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
